<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Boosting Monocular Depth Estimation to High Resolution &#8211; Yağız Aksoy</title>
<meta name="description" content="Boosting Monocular Depth Estimation to High Resolution">



<!-- Twitter Cards -->
<meta name="twitter:title" content="Boosting Monocular Depth Estimation to High Resolution">
<meta name="twitter:description" content="Boosting Monocular Depth Estimation to High Resolution">
<meta name="twitter:site" content="@yagizaksoy">
<meta name="twitter:creator" content="@yagizaksoy">

<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://yaksoy.github.io/images/mahdiMScTeaser.jpg">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Boosting Monocular Depth Estimation to High Resolution">
<meta property="og:description" content="Boosting Monocular Depth Estimation to High Resolution">
<meta property="og:url" content="http://yaksoy.github.io/bmd-msc/">
<meta property="og:site_name" content="Yağız Aksoy">

<!-- Webmaster Tools verfication -->
<meta name="google-site-verification" content="googleb0479c04a25255c3">



<link rel="canonical" href="http://yaksoy.github.io/bmd-msc/">
<link href="http://yaksoy.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Yağız Aksoy Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://yaksoy.github.io/assets/css/main.css">
<!-- Webfonts -->
<script src="//use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://yaksoy.github.io/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://yaksoy.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://yaksoy.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://yaksoy.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://yaksoy.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://yaksoy.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://yaksoy.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://yaksoy.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://yaksoy.github.io/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="page">

<div id="main" role="main">
  <article class="entry">
    <div class="entry-wrapper">
      <br>
      <div class="entry-titleLogos">
        <table><colgroup><col style="width:50%" /><col style="width:50%" /></colgroup><tr><td style="text-align:left"><a href="https://www.sfu.ca/computing.html" target="_blank"><img src="../images/sfu.png" class="proj-logo" title="SFU"></a></td><td style="text-align:right"><a href="../group/" target="_blank"><img src="../images/cplab-full.png" class="proj-logo" title="CPLab" style="float:right;"></a></td></tr></table>
      </div>
      <br>
      <!-- <header class="entry-header">-->
        <h1 class="entry-titleProject" style="margin-top:5px;">Boosting Monocular Depth Estimation to High Resolution</h1>
      <!-- </header>-->
      <div class="entry-titleAuthors">
        <table style="text-align:center;"><tr><td><a href="http://miangoleh.github.io/" target="_blank"><img src="../group/mahdi.jpg" class="proj-photo" title="Mahdi"></a></td></tr><tr><td><a href="http://miangoleh.github.io/" target="_blank">Seyed Mahdi Hosseini Miangoleh</a></td></tr></table>
      </div>
      <div class="entry-titleVenue">
        MSc Thesis<br> Simon Fraser University, 2022
      </div>
    </div><!-- /.entry-wrapper -->
    <img src="http://yaksoy.github.io/images/mahdiMScTeaser.jpg" class="entry-feature-image" alt="Boosting Monocular Depth Estimation to High Resolution" style="margin-top:-40;"><p class="image-caption">Depth maps generated for Fresco by Raphael in the Vatican City known as School of Athens by our method. This result was featured by Nature in their <a href="https://www.nature.com/immersive/d41586-021-02307-x/index.html" target = "_blank">Best Science Images of the Month - August 2021</a> selection.</p>
    <div class="entry-wrapper">
      <div class="entry-contentProject">
        <p style="text-align:center;"><b>Abstract</b></p>

<p>
Convolutional neural networks have shown a remarkable ability to estimate depth from a single image. 
However, the estimated depth maps are low resolution due to network structure and hardware limitations, only showing the overall scene structure and lacking fine details, which limits their applicability. 
We demonstrate that there is a trade-off between the consistency of the scene structure and the high-frequency details concerning input content and resolution. 
Building upon this duality, we present a double estimation framework to improve the depth estimation of the whole image and a patch selection step to add more local details. 
Our approach obtains multi-megapixel depth estimations with sharp details by merging estimations at different resolutions based on image content. 
A key strength of our approach is that we can employ any off-the-shelf pre-trained CNN-based monocular depth estimation model without requiring further finetuning.
</p>

<p style="text-align:center;"><b>Dissertation</b></p>
<table style="text-align:center;"><tr>
		<td><a href="https://sfu.ca/~smh31/masterthesis" target="_blank"><img width="200" src="http://yaksoy.github.io/images/research/SFU22MahdiPaper.jpg" title="Thesis" /></a></td>
	</tr></table>

<p style="text-align:center;"><b>Video Presentation</b></p>

<p style="text-align:center;">
<iframe width="560" height="315" src="https://www.youtube.com/embed/DZ0ft1l50KY" frameborder="0"> </iframe>
</p>

<p style="text-align:center;"><b>BibTeX</b></p>
<p>
<div class="pub-bibtex">
	@MASTERSTHESIS{bmd-msc,<br />
	author={Seyed Mahdi Hosseini Miangoleh},<br />
	title={Boosting Monocular Depth Estimation to High Resolution},<br />
	year={2022},<br />
	school={Simon Fraser University},<br />
  }
  </div>
  </p>

<p style="text-align:center;"><b>Publications in the context of this thesis</b></p>

<hr />

<table>
<tr>
<td class="pub-photocol">
<a href="../highresdepth" target="_blank"><img src="http://yaksoy.github.io/images/research/highresdepth.jpg" class="pub-photo" /></a>
</td>
<td>
<div class="pub-title">
	<a href="../highresdepth" target="_blank">Boosting Monocular Depth Estimation Models to High Resolution via Content Adaptive Multi Resolution Merging <i class="fa fa-external-link"></i></a>
</div>
<div class="pub-authors">
	<i><b>S. Mahdi H. Miangoleh*</b></i>, <i><b>Sebastian Dille*</b></i>, Long Mai, Sylvain Paris, and <b>Yağız Aksoy</b> 
</div>
<div class="pub-venue">
	CVPR, 2021
</div>

<div class="accordion">
  <input id="CVPR21-item1" name="accordion1" type="checkbox" />
  <label for="CVPR21-item1">Abstract</label>
  <div class="pub-abstract">
	Neural networks have shown great abilities in estimating depth from a single image. 
	However, the inferred depth maps are well below one-megapixel resolution and often lack fine-grained details, which limits their practicality. 
	Our method builds on our analysis on how the input resolution and the scene structure affects depth estimation performance. 
	We demonstrate that there is a trade-off between a consistent scene structure and the high-frequency details, and merge low- and high-resolution estimations to take advantage of this duality using a simple depth merging network. 
	We present a double estimation method that improves the whole-image depth estimation and a patch selection method that adds local details to the final result. 
	We demonstrate that by merging estimations at different resolutions with changing context, we can generate multi-megapixel depth maps with a high level of detail using a pre-trained model.
</div>

  <input id="CVPR21-item2" name="accordion1" type="checkbox" />
  <label for="CVPR21-item2">Manuscript &amp; more</label>
  <div class="pub-photolink">
  
	<table><tr>
		<td><a href="http://yaksoy.github.io/papers/CVPR21-HighResDepth.pdf" target="_blank"><img width="200" src="http://yaksoy.github.io/images/research/CVPR21Paper.jpg" title="Paper" /></a></td>
		<td><a href="http://yaksoy.github.io/papers/CVPR21-HighResDepth-Supp.pdf" target="_blank"><img width="200" src="http://yaksoy.github.io/images/research/CVPR21Supp.jpg" title="Paper" /></a></td>
		<td><a href="https://youtu.be/lDeI17pHlqo" target="_blank"><img src="http://yaksoy.github.io/images/research/CVPR21Video.jpg" title="Video" /></a></td>
	</tr></table>
	</div>

  <input id="CVPR21-item3" name="accordion1" type="checkbox" />
  <label for="CVPR21-item3">BibTeX</label>
  <div class="pub-bibtex">
@INPROCEEDINGS{Miangoleh2021Boosting,<br />
	author={S. Mahdi H. Miangoleh and Sebastian Dille and Long Mai and Sylvain Paris and Ya\u{g}{\i}z Aksoy},<br />
	title={Boosting Monocular Depth Estimation Models to High-Resolution via Content-Adaptive Multi-Resolution Merging},<br />
	journal={Proc. CVPR},<br />
	year={2021},<br />
	} 
  </div>
</div>
</td>
</tr>
</table>


      </div><!-- /.entry-contentProject -->
    </div><!-- /.entry-wrapper -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<span>&copy; 2023 Yagiz Aksoy</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://yaksoy.github.io';
</script>

<!-- Include Latex style math -->
<!-- https://stackoverflow.com/questions/10987992/using-mathjax-with-jekyll -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://yaksoy.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://yaksoy.github.io/assets/js/scripts.min.js"></script>



<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11195487; 
var sc_invisible=1; 
var sc_security="112d9b46"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="shopify
analytics" href="http://statcounter.com/shopify/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11195487/0/112d9b46/1/"
alt="shopify analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->

</body>
</html>
