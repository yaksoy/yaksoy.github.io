<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Computational Photography and Image Manipulation &#8211; Yağız Aksoy</title>
<meta name="description" content="PhD">



<!-- Twitter Cards -->
<meta name="twitter:title" content="Computational Photography and Image Manipulation">
<meta name="twitter:description" content="PhD">
<meta name="twitter:site" content="@yagizaksoy">
<meta name="twitter:creator" content="@yagizaksoy">

<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yaksoy.github.io/images/jordan.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Computational Photography and Image Manipulation">
<meta property="og:description" content="PhD">
<meta property="og:url" content="https://yaksoy.github.io/cpim/">
<meta property="og:site_name" content="Yağız Aksoy">

<!-- Webmaster Tools verfication -->
<meta name="google-site-verification" content="googleb0479c04a25255c3">



<link rel="canonical" href="https://yaksoy.github.io/cpim/">
<link href="https://yaksoy.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Yağız Aksoy Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="https://yaksoy.github.io/assets/css/main.css">
<!-- Webfonts -->
<script src="//use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="https://yaksoy.github.io/assets/js/vendor/html5shiv.min.js"></script>
  <script src="https://yaksoy.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="https://yaksoy.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="https://yaksoy.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="https://yaksoy.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="https://yaksoy.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://yaksoy.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://yaksoy.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://yaksoy.github.io/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="page">

<div id="main" role="main">
  <article class="entry">
    <div class="entry-wrapper">
      <br>
      <div class="entry-titleLogos">
        
      </div>
      <br>
      <!-- <header class="entry-header">-->
        <h1 class="entry-titleProject" style="margin-top:5px;">Computational Photography and Image Manipulation</h1>
      <!-- </header>-->
      <div class="entry-titleAuthors">
        CMPT 461 / 769, Spring 2024, with full online support
      </div>
      <div class="entry-titleVenue">
        
      </div>
    </div><!-- /.entry-wrapper -->
    
    <div class="entry-wrapper">
      <div class="entry-contentProject">
        <p>Instructor: <a href="../" target="_blank">Yağız Aksoy</a></p>

<p>TA: Chris Careaga</p>

<p>Wed 13:30 – 14:20; Fri 12:30 – 14:20</p>

<p>In this course, we will cover some of the fundamental research topics in computational photography and image manipulation and have a look at the state-of-the-art research going on in the field, where students develop custom computational photography applications. The course is offered in-person with an option to participate over Zoom.</p>

<p>Modern computational photography takes its powers from computer vision methods that works at high resolutions in-the-wild and applies them to re-render new photographs using techniques in computer graphics. This course covers computational photography from practical and theoretical perspectives. Students will get an overview of classical and modern formulations in computational photography research and also develop custom practical applications. In the first few weeks, we cover fundamental computational photography concepts, formulations, and applications and also in real-world film production environments through guest lectures. The latter part of the course follows a curriculum focused on recent/current research. 2 hours of each week is dedicated to deep dives to fundamental topics in image manipulation including monocular depth estimation, intrinsic decomposition, soft segmentation and alpha matting, image recoloring, and more. 1 hour each week is reserved for all-together open-ended discussions on term projects and research papers. Students form project groups and each projects develops their own photography project through discussions with the instructor. Each student also prepares a detailed video presentation of a selected research paper, which is watched and discussed together in class at the end of the semester. The collaboration is enhanced through weekly check-ins and discussions during lecture hours. 
</p>

<p>
Attendence to lectures, with in-person and Zoom options, are mandatory for the entire semester.
</p>

<p style="text-align:center;"><b>What will you get out of this course?</b></p>
<p>You will learn</p>
<ul>
  <li>
    <p>fundamental concepts that connect photography and image manipulation to computer vision and image processing.</p>
  </li>
  <li>
    <p>many different aspects and application scenarios of current computational photography research.</p>
  </li>
  <li>
    <p>the math behind important movie post-production techniques such as green-screen keying, HDR tonemapping, and color editing.</p>
  </li>
  <li>
    <p>how to develop a unique computational photography project using cutting edge methods.</p>
  </li>
  <li>
    <p>important image processing techniques that will help you develop better computer vision and computer graphics systems.</p>
  </li>
  <li>
    <p>important mathematical foundations of visual computing such as graph-based formulations, large linear systems, and spectral analysis.</p>
  </li>
  <li>
    <p>effective video making and scientific communication skills that are becoming perhaps as important as technical presentation skills in today's online research world.</p>
  </li>
</ul>

<p>It’s probably a good idea for the most of you to brush up on your linear algebra skills as soon as possible to make the best out of this class. <a href="https://www.youtube.com/playlist?list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B" target="_blank"><b>3Blue1Brown</b> has introductory Linear Algebra classes on Youtube with great visual explanations of concepts that we will make use of during the class.</a></p>

<p>This course builds up on CMPT 361. A refresher on the camera model and image processing fundamentals is advised before taking this course. You can check out <a href="https://youtube.com/playlist?list=PLj_KB0_j7uisjG2NLhSkn3Jcd4fB9yeWp
" target="_blank"><b>this playlist of related topics</b> from CMPT 361 - Intro. Visual Computing here.</a></p>

<p style="text-align:center;"><b>COVID-19 Policy</b></p>
<p>
 In order to have a safe learning environment for everyone, we have several guidelines for in-person lectures:
  <br />
   - <b>If you are feeling sick</b> or you suspect you might have contracted COVID-19, <b>please do not attend the in-person lectures</b> and instead join the Zoom sessions.
    <br />
  - <b>If you have contracted COVID-19</b>, please do not attent the in-person lectures <b>for 2 weeks after your initial diagnosis</b>. Please join the Zoom sessions instead.
</p>

<p style="text-align:center;"><b>Grading</b></p>

<p>Programming assignments - 2 x 10 (461) or 2 x 5 + 10 (769) = <b>20%</b></p>
<p>Paper discussion and video - <b>30%</b></p>
<p>Group project = <b>50%</b></p>

<p style="text-align:center;"><b>Tentative Schedule -- expect some changes</b></p>

<table>
<tr>
<td colspan="3"><p style="text-align:center;margin:0;padding:0;"><b>Week 1:  Entering the Computational Photography research field, background on CV, image processing, photography, video making</b></p></td>
</tr>
<tr>
<td colspan="3"><p style="text-align:center;margin:0;padding:0;"><b>Week 2: Cameras and Color</b></p></td>
</tr>
<tr>
<td colspan="3"><p style="text-align:center;margin:0;padding:0;"><b>Week 3: Cameras and Color, HDR, Tonemapping</b></p></td>
</tr>
<tr>
<td colspan="3"><p style="text-align:center;margin:0;padding:0;">Project groups formed</p></td>
</tr>
<tr>
<td colspan="3"><p style="text-align:center;margin:0;padding:0;"><b>Week 4: Tonemapping, Bilateral Filtering, Image Blending</b></p></td>
</tr>
<tr>
<td rowspan="9"><p style="text-align:center;margin:0;padding:0;">Quick paper discussions and project updates on Wednesdays</p></td>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 5: Image Blending and Boundary Minimization</b></p></td>
</tr>
<tr>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 6: Natural Image Matting</b><br />Paper assignments</p></td>
</tr>
<tr style="background-color:lightgray;">
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Feb 19-25: Reading Break</b></p></td>
</tr>
<tr>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 7: Soft Color Segmentation</b><br />Deadline for all assignments</p></td>
</tr>
<tr>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 8: Intrinsic Decomposition</b></p></td>
</tr>
<tr>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 9: Monocular Depth Estimation</b></p></td>
</tr>
<tr>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 10: Deep Image Editing</b></p></td>
</tr>
<tr>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 11: RGB-Space Geometry</b></p></td>
</tr>
<tr>
<td colspan="2"><p style="text-align:center;margin:0;padding:0;"><b>Week 12: Practical Applications for Film Editing (Guest lecture)</b></p></td>
</tr>
<tr>
<td colspan="3"><p style="text-align:center;margin:0;padding:0;"><b>Week 13: Current Research through Student Videos</b></p></td>
<td style="background-color:lightgray;"><p style="text-align:center;margin:0;padding:0;"></p></td>
</tr>
</table>

<p style="text-align:center;"><b>Programming assignments</b></p>

<p>There will be 3 programming assignments for 985 (grad) students, and 2 programming assignments for 461 (undergrad). </p>

<p style="text-align:center;"><a href="./p3/" target="_blank"> <b> Assignment 1: Texture synthesis. CMPT 461 and CMPT 985</b></a></p>

<p style="text-align:center;"><a href="./p4/" target="_blank"> <b> Assignment 2: Poisson blending. CMPT 461 and CMPT 985.</b></a></p>

<p style="text-align:center;"><a href="./p2/" target="_blank"> <b> Assignment 3: Iterative edge-aware filtering. Only CMPT 985.</b></a></p>

<p style="text-align:center;"><b>Paper reading</b></p>

<p>Each student will be assigned a recent research paper. You will give a quick overview during one of the discussion hours on Mondays. You will then prepare a video describing the paper. We will talk about how to prepare these videos in detail later in the semester.</p>

<p><b>For year-by-year listings of SIGGRAPH and SIGGRAPH Asia papers</b>, see <a href="http://kesen.realtimerendering.com
" target="_blank">Ke-Sen Huang's Home Page <i class="fa fa-external-link"></i></a>.
</p>

<p style="text-align:center;"><b>Projects</b></p>

<p>You will develop a computational photography project throughout the semester. These projects will focus on computational photography and image manipulation applications. There will be a set of options for project topics for you to choose from. ou can also develop your own idea. We will design and develop them together through in-class discussions.</p>

<p>At the end of the semester, you will prepare a video on your projct and your application results. We will talk about how to prepare these videos in detail later in the semester.</p>

<p style="text-align:center;"><b>Publications from Past Student Projects</b></p>

<p>Student-led projects focus on new tools and applications in the computational photography domain and some of them become a great match for SIGGRAPH (Asia) poster programs.<a href="https://www.sfu.ca/computing/newsandevents/2022/two-computing-science-undergraduate-projects-feature-at-siggraph.html" target="_blank">SFU CS featured a story on our undergrad authors in 2022.</a></p>

<hr />

<table>
<tr>
<td class="pub-photocol">
<a href="../dynapix" target="_blank"><img src="https://yaksoy.github.io/images/research/dynapix.jpg" class="pub-photo" /></a>
</td>
<td>
<div class="pub-title">
	<a href="../dynapix" target="_blank">DynaPix: Normal Map Pixelization for Dynamic Lighting <i class="fa fa-external-link"></i></a>
</div>
<div class="pub-authors">
	Gerardo Gandeaga, Denys Iliash, <b>Chris Careaga</b>, and <b>Yağız Aksoy</b> 
</div>
<div class="pub-venue">
	SIGGRAPH Posters, 2022
</div>

<div class="pub-accordion">
  <input id="SIG22b-item1" name="accordion1" type="checkbox" />
  <label for="SIG22b-item1">Abstract</label>
  <div class="pub-abstract">
	This work introduces DynaPix, a Krita extension that automatically generates pixelated images and surface normals from an input image. 
	DynaPix is a tool that aids pixel artists and game developers more efficiently develop 8-bit style games and bring them to life with dynamic lighting through normal maps that can be used in modern game engines such as Unity. 
	The extension offers artists a degree of flexibility as well as allows for further refinements to generated artwork. 
	Powered by out of the box solutions, DynaPix is a tool that seamlessly integrates in the artistic workflow.
  </div>

  <input id="SIG22b-item2" name="accordion1" type="checkbox" />
  <label for="SIG22b-item2">Manuscript &amp; more</label>
  <div class="pub-photolink">
  
	<table><tr>
		<td><a href="https://yaksoy.github.io/papers/SIG22b-DynaPix.pdf" target="_blank"><img width="200" src="https://yaksoy.github.io/images/research/dynapixPaper.jpg" title="Paper" /></a></td>
		<td><a href="https://yaksoy.github.io/papers/SIG22b-DynaPix.jpg" target="_blank"><img width="200" src="https://yaksoy.github.io/images/research/dynapixPosterSmall.jpg" title="Poster" /></a></td>
		<td><a href="https://youtu.be/1mylyzw6i_U" target="_blank"><img src="https://yaksoy.github.io/images/research/dynapixVideo.jpg" title="Video" /></a></td>
	</tr></table>
	</div>

  <input id="SIG22b-item3" name="accordion1" type="checkbox" />
  <label for="SIG22b-item3">BibTeX</label>
  <div class="pub-bibtex">
	@INPROCEEDINGS{dynapix,<br />
	author={Gerardo Gandeaga and Denys Iliash and Chris Careaga and Ya\u{g}{\i}z Aksoy},<br />
	title={Dyna{P}ix: Normal Map Pixelization for Dynamic Lighting},<br />
	booktitle={SIGGRAPH Posters},<br />
	year={2022},<br />
	}
  </div>
</div>
</td>
</tr>
</table>

<hr />

<table>
<tr>
<td class="pub-photocol">
<a href="../parallaxbg" target="_blank"><img src="https://yaksoy.github.io/images/research/parallax.jpg" class="pub-photo" /></a>
</td>
<td>
<div class="pub-title">
	<a href="../parallaxbg" target="_blank">Parallax Background Texture Generation <i class="fa fa-external-link"></i></a>
</div>
<div class="pub-authors">
	Brigham Okano, Shao Yu Shen, <b>Sebastian Dille</b>, and <b>Yağız Aksoy</b> 
</div>
<div class="pub-venue">
	SIGGRAPH Posters, 2022
</div>

<div class="pub-accordion">
  <input id="SIG22c-item1" name="accordion1" type="checkbox" />
  <label for="SIG22c-item1">Abstract</label>
  <div class="pub-abstract">
	Art assets for games can be time intensive to produce. 
	Whether it is a full 3D world, or simpler 2D background, creating good looking assets takes time and skills that are not always readily available. 
	Time can be saved by using repeating assets, but visible repetition hurts immersion. 
	Procedural generation techniques can help make repetition less uniform, but do not remove it entirely. 
	Both approaches leave noticeable levels of repetition in the image, and require significant time and skill investments to produce. 
	Video game developers in hobby, game jam, or early prototyping situations may not have access to the required time and skill. 
	We propose a framework to produce layered 2D backgrounds without the need for significant artist time or skill. 
	In our pipeline, the user provides segmented photographic input, instead of creating traditional art, and receives game-ready assets. 
	By utilizing photographs as input, we can achieve both a high level of realism for the resulting background texture as well as a shift from manual work away towards computational run-time which frees up developers for other work.
  </div>

  <input id="SIG22c-item2" name="accordion1" type="checkbox" />
  <label for="SIG22c-item2">Manuscript &amp; more</label>
  <div class="pub-photolink">
  
	<table><tr>
		<td><a href="https://yaksoy.github.io/papers/SIG22c-ParallaxBG.pdf" target="_blank"><img width="200" src="https://yaksoy.github.io/images/research/parallaxPaper.jpg" title="Paper" /></a></td>
		<td><a href="https://yaksoy.github.io/papers/SIG22c-ParallaxBG.jpg" target="_blank"><img width="200" src="https://yaksoy.github.io/images/research/parallaxPosterSmall.jpg" title="Poster" /></a></td>
		<td><a href="https://youtu.be/_KWdFy3YipI" target="_blank"><img src="https://yaksoy.github.io/images/research/parallaxVideo.jpg" title="Video" /></a></td>
	</tr></table>
	</div>

  <input id="SIG22c-item3" name="accordion1" type="checkbox" />
  <label for="SIG22c-item3">BibTeX</label>
  <div class="pub-bibtex">
	@INPROCEEDINGS{parallaxBG,<br />
	author={Brigham Okano and Shao Yu Shen and Sebastian Dille and Ya\u{g}{\i}z Aksoy},<br />
	title={Parallax Background Texture Generation},<br />
	booktitle={SIGGRAPH Posters},<br />
	year={2022},<br />
	}
  </div>
</div>
</td>
</tr>
</table>

<hr />

<table>
<tr>
<td class="pub-photocol">
<a href="../datamosh" target="_blank"><img src="https://yaksoy.github.io/images/research/datamosh.jpg" class="pub-photo" /></a>
</td>
<td>
<div class="pub-title">
	<a href="../datamosh" target="_blank">Datamoshing with Optical Flow <i class="fa fa-external-link"></i></a>
</div>
<div class="pub-authors">
	<b>Chris Careaga</b>, <b>Mahesh Kumar Krishna Reddy</b>, and <b>Yağız Aksoy</b> 
</div>
<div class="pub-venue">
	SIGGRAPH Asia Posters, 2023
</div>

<div class="pub-accordion">
  <input id="SIGa23p-item1" name="accordion1" type="checkbox" />
  <label for="SIGa23p-item1">Abstract</label>
  <div class="pub-abstract">
	We propose a simple method for emulating the effect of data moshing, without relying on the corruption of encoded video, and explore its use in different application scenarios. 
	Like traditional data moshing, we apply motion information to mismatched visual data.
	Our approach uses off-the-shelf optical flow estimation to generate motion vectors for each pixel. 
	Our core algorithm can be implemented in a handful of lines but unlocks multiple video editing effects. 
	The use of accurate optical flow rather than compression data also creates a more natural transition without block artifacts. 
	We hope our method provides artists and content creators with more creative freedom over the process of data moshing.
  </div>

  <input id="SIGa23p-item2" name="accordion1" type="checkbox" />
  <label for="SIGa23p-item2">Manuscript &amp; more</label>
  <div class="pub-photolink">
  
	<table><tr>
		<td><a href="https://yaksoy.github.io/papers/SIGa23p-Datamosh.pdf" target="_blank"><img width="200" src="https://yaksoy.github.io/images/research/datamoshPaper.jpg" title="Paper" /></a></td>
		<td><a href="https://yaksoy.github.io/papers/SIGa23p-Datamosh.jpg" target="_blank"><img width="200" src="https://yaksoy.github.io/images/research/datamoshPosterSmall.jpg" title="Poster" /></a></td>
	</tr></table>
	</div>

  <input id="SIGa23p-item3" name="accordion1" type="checkbox" />
  <label for="SIGa23p-item3">BibTeX</label>
  <div class="pub-bibtex">
@INPROCEEDINGS{datamosh,<br />
	author={Chris Careaga and Mahesh Kumar Krishna Reddy and Ya\u{g}{\i}z Aksoy},<br />
	title={Datamoshing with Optical Flow},<br />
	booktitle={SIGGRAPH Asia Posters},<br />
	year={2023},<br />
	}
  </div>
</div>
</td>
</tr>
</table>

<hr />

<p style="text-align:center;"><b>Student Paper and Project Videos from Past Offerings</b></p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/videoseries?list=PLj_KB0_j7uivzKqvlyjL2LRft9CKEHOHL" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<iframe width="560" height="315" src="https://www.youtube.com/embed/videoseries?list=PLj_KB0_j7uis6ek7h0DvU04W8lLWe-qII" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p style="text-align:center;"><b>Textbook</b></p>

<p>There is no required textbook for the course. One useful resource that is also available online for free is the textbook <a href="http://szeliski.org/Book/" target="_blank">Computer Vision: Algorithms and Applications</a> by Richard Szeliski. There is a great number of resources you can find online, and don't forget that Wikipedia is always your friend.</p>

<p style="text-align:center;"><b>Announcements, Questions and Discussion</b></p>

<p>Make sure to check Coursys for current updates.</p>

<p style="text-align:center;"><b>Academic Integrity</b></p>

<p>You are encouraged to talk about and discuss coding assignments and projects with your class-mates. You are allowed to use existing code/library (e.g., optimization library or vector calculus library), in which case, you have to explicitly describe it in your report. Besides the above case, every single line of code must be written by you, and you are not allowed to copy from other sources. Writing the code by exactly or closely following existing code is not technically copy-and-paste, but is also considered to be copy-and-paste. Use your fair judgement. You know what is good and bad. When in doubt, consult the instructor. You are expected to maintain the highest standards of academic integrity and refrain from the forms of misconduct.</p>

<p style="text-align:center;"><b>Past Offerings</b></p>

<p><a href="/cpim/2022" target="_blank"><b>2023 Spring</b> - CMPT 461/769 - Computational Photography and Image Manipulation <i class="fa fa-external-link"></i></a></p>

<p><a href="/cpim/2022" target="_blank"><b>2022 Spring</b> - CMPT 461/769- Computational Photography and Image Manipulation <i class="fa fa-external-link"></i></a></p>

<p><a href="/cpim/2021" target="_blank"><b>2021 Spring</b> - CMPT 461/985 - Computational Photography and Image Manipulation <i class="fa fa-external-link"></i></a></p>

<p><a href="/cpim/2019" target="_blank"><b>2019 Fall</b> - CMPT 469/985 - Computational Photography and Image Manipulation (Special Topics) <i class="fa fa-external-link"></i></a></p>

      </div><!-- /.entry-contentProject -->
    </div><!-- /.entry-wrapper -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<span>&copy; 2023 Yagiz Aksoy</span>
  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'https://yaksoy.github.io';
</script>

<!-- Include Latex style math -->
<!-- https://stackoverflow.com/questions/10987992/using-mathjax-with-jekyll -->
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="https://yaksoy.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="https://yaksoy.github.io/assets/js/scripts.min.js"></script>



<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11195487; 
var sc_invisible=1; 
var sc_security="112d9b46"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript><div class="statcounter"><a title="shopify
analytics" href="http://statcounter.com/shopify/"
target="_blank"><img class="statcounter"
src="//c.statcounter.com/11195487/0/112d9b46/1/"
alt="shopify analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->

</body>
</html>
